import "std/common.cup"

enum TokenType {
    // Keywords go below:
    TOKEN_BREAK,
    TOKEN_CASE,
    TOKEN_CHAR,
    TOKEN_CONST,
    TOKEN_DEFAULT,
    TOKEN_ENUM,
    TOKEN_ELSE,
    TOKEN_DEFER,
    TOKEN_F64,
    TOKEN_FN,
    TOKEN_FOR,
    TOKEN_IF,
    TOKEN_INT,
    TOKEN_I8,
    TOKEN_I16,
    TOKEN_I32,
    TOKEN_I64,
    TOKEN_LET,
    TOKEN_METHOD,
    TOKEN_RETURN,
    TOKEN_SIZEOF,
    TOKEN_STATIC_ASSERT,
    TOKEN_STRUCT,
    TOKEN_SWITCH,
    TOKEN_UNION,
    TOKEN_VOID,
    TOKEN_WHILE,
    TOKEN_IMPORT,
    TOKEN_NEW,

    NUM_KEYWORDS, // End of keywords

    TOKEN_AMPERSAND,
    TOKEN_AND,
    TOKEN_ASSIGN,
    TOKEN_BAR,
    TOKEN_CARET,
    TOKEN_CHARLIT,
    TOKEN_CLOSE_BRACE,
    TOKEN_CLOSE_BRACKET,
    TOKEN_CLOSE_PAREN,
    TOKEN_COLON,
    TOKEN_COLONCOLON,
    TOKEN_COMMA,
    TOKEN_DOT,
    TOKEN_EOF,
    TOKEN_EQ,
    TOKEN_EXCLAMATION,
    TOKEN_FLOATLIT,
    TOKEN_GEQ,
    TOKEN_GT,
    TOKEN_IDENTIFIER,
    TOKEN_INTLIT,
    TOKEN_LEQ,
    TOKEN_LSHIFT,
    TOKEN_LT,
    TOKEN_MINUS,
    TOKEN_MINUSEQUALS,
    TOKEN_MINUSMINUS,
    TOKEN_NEQ,
    TOKEN_OPEN_BRACE,
    TOKEN_OPEN_BRACKET,
    TOKEN_OPEN_PAREN,
    TOKEN_OR,
    TOKEN_PERCENT,
    TOKEN_PLUS,
    TOKEN_PLUSEQUALS,
    TOKEN_PLUSPLUS,
    TOKEN_QUESTION,
    TOKEN_RSHIFT,
    TOKEN_SEMICOLON,
    TOKEN_SLASH,
    TOKEN_STAR,
    TOKEN_STRINGLIT,
    TOKEN_TILDE,
    TOKEN_XOR,

    NUM_TOKEN_TYPES,
};

struct Location {
    filename: char*;
    line: int;
    col: int;
};

struct Token {
    typ: int;
    loc: Location;
    value: union {
        as_int: int;
        as_string: char*;
        as_char: char;
        as_float_str: char*;
    };
};

fn token_type_to_string(typ: int): char* {
    static_assert(NUM_TOKEN_TYPES == 74, "Exhaustive match in token_type_to_string");
    switch (typ) {
        case TOKEN_AMPERSAND:     return "TOKEN_AMPERSAND";
        case TOKEN_AND:           return "TOKEN_AND";
        case TOKEN_ASSIGN:        return "TOKEN_ASSIGN";
        case TOKEN_BAR:           return "TOKEN_BAR";
        case TOKEN_CARET:         return "TOKEN_CARET";
        case TOKEN_CHARLIT:       return "TOKEN_CHARLIT";
        case TOKEN_CLOSE_BRACE:   return "TOKEN_CLOSE_BRACE";
        case TOKEN_CLOSE_BRACKET: return "TOKEN_CLOSE_BRACKET";
        case TOKEN_CLOSE_PAREN:   return "TOKEN_CLOSE_PAREN";
        case TOKEN_COLON:         return "TOKEN_COLON";
        case TOKEN_COLONCOLON:    return "TOKEN_COLONCOLON";
        case TOKEN_COMMA:         return "TOKEN_COMMA";
        case TOKEN_DOT:           return "TOKEN_DOT";
        case TOKEN_EOF:           return "TOKEN_EOF";
        case TOKEN_EQ:            return "TOKEN_EQ";
        case TOKEN_EXCLAMATION:   return "TOKEN_EXCLAMATION";
        case TOKEN_GEQ:           return "TOKEN_GEQ";
        case TOKEN_GT:            return "TOKEN_GT";
        case TOKEN_IDENTIFIER:    return "TOKEN_IDENTIFIER";
        case TOKEN_FLOATLIT:      return "TOKEN_FLOATLIT";
        case TOKEN_INTLIT:        return "TOKEN_INTLIT";
        case TOKEN_LEQ:           return "TOKEN_LEQ";
        case TOKEN_LSHIFT:        return "TOKEN_LSHIFT";
        case TOKEN_LT:            return "TOKEN_LT";
        case TOKEN_MINUS:         return "TOKEN_MINUS";
        case TOKEN_MINUSEQUALS:   return "TOKEN_MINUSEQUALS";
        case TOKEN_MINUSMINUS:    return "TOKEN_MINUSMINUS";
        case TOKEN_NEQ:           return "TOKEN_NEQ";
        case TOKEN_OPEN_BRACE:    return "TOKEN_OPEN_BRACE";
        case TOKEN_OPEN_BRACKET:  return "TOKEN_OPEN_BRACKET";
        case TOKEN_OPEN_PAREN:    return "TOKEN_OPEN_PAREN";
        case TOKEN_OR:            return "TOKEN_OR";
        case TOKEN_PERCENT:       return "TOKEN_PERCENT";
        case TOKEN_PLUS:          return "TOKEN_PLUS";
        case TOKEN_PLUSEQUALS:    return "TOKEN_PLUSEQUALS";
        case TOKEN_PLUSPLUS:      return "TOKEN_PLUSPLUS";
        case TOKEN_QUESTION:      return "TOKEN_QUESTION";
        case TOKEN_RSHIFT:        return "TOKEN_RSHIFT";
        case TOKEN_SEMICOLON:     return "TOKEN_SEMICOLON";
        case TOKEN_SLASH:         return "TOKEN_SLASH";
        case TOKEN_STAR:          return "TOKEN_STAR";
        case TOKEN_STRINGLIT:     return "TOKEN_STRINGLIT";
        case TOKEN_TILDE:         return "TOKEN_TILDE";
        case TOKEN_XOR:           return "TOKEN_XOR";

        // Keywords just grouped separately
        case TOKEN_BREAK:         return "TOKEN_BREAK";
        case TOKEN_CASE:          return "TOKEN_CASE";
        case TOKEN_CHAR:          return "TOKEN_CHAR";
        case TOKEN_CONST:         return "TOKEN_CONST";
        case TOKEN_DEFAULT:       return "TOKEN_DEFAULT";
        case TOKEN_ENUM:          return "TOKEN_ENUM";
        case TOKEN_ELSE:          return "TOKEN_ELSE";
        case TOKEN_DEFER:         return "TOKEN_DEFER";
        case TOKEN_F64:           return "TOKEN_F64";
        case TOKEN_FN:            return "TOKEN_FN";
        case TOKEN_FOR:           return "TOKEN_FOR";
        case TOKEN_IF:            return "TOKEN_IF";
        case TOKEN_INT:           return "TOKEN_INT";
        case TOKEN_I8:            return "TOKEN_I8";
        case TOKEN_I16:           return "TOKEN_I16";
        case TOKEN_I32:           return "TOKEN_I32";
        case TOKEN_I64:           return "TOKEN_I64";
        case TOKEN_LET:           return "TOKEN_LET";
        case TOKEN_METHOD:        return "TOKEN_METHOD";
        case TOKEN_RETURN:        return "TOKEN_RETURN";
        case TOKEN_SIZEOF:        return "TOKEN_SIZEOF";
        case TOKEN_STATIC_ASSERT: return "TOKEN_STATIC_ASSERT";
        case TOKEN_STRUCT:        return "TOKEN_STRUCT";
        case TOKEN_SWITCH:        return "TOKEN_SWITCH";
        case TOKEN_UNION:         return "TOKEN_UNION";
        case TOKEN_VOID:          return "TOKEN_VOID";
        case TOKEN_WHILE:         return "TOKEN_WHILE";
        case TOKEN_IMPORT:        return "TOKEN_IMPORT";
	case TOKEN_NEW:           return "TOKEN_NEW";
    }

    putsln("\nUnknown token type in token_type_to_string: "); print(typ);
    exit(1);
}

fn keyword_to_string(typ: int): char* {
    static_assert(NUM_KEYWORDS == 29, "Exhaustive match in keyword_to_string");
    switch (typ) {
        case TOKEN_BREAK: return "break";
        case TOKEN_CASE: return "case";
        case TOKEN_CHAR: return "char";
        case TOKEN_CONST: return "const";
        case TOKEN_DEFAULT: return "default";
        case TOKEN_ENUM: return "enum";
        case TOKEN_ELSE: return "else";
        case TOKEN_DEFER: return "defer";
        case TOKEN_F64: return "f64";
        case TOKEN_FN: return "fn";
        case TOKEN_FOR: return "for";
        case TOKEN_IF: return "if";
        case TOKEN_INT: return "int";
        case TOKEN_I8: return "i8";
        case TOKEN_I16: return "i16";
        case TOKEN_I32: return "i32";
        case TOKEN_I64: return "i64";
        case TOKEN_LET: return "let";
        case TOKEN_METHOD: return "method";
        case TOKEN_RETURN: return "return";
        case TOKEN_SIZEOF: return "sizeof";
        case TOKEN_STATIC_ASSERT: return "static_assert";
        case TOKEN_STRUCT: return "struct";
        case TOKEN_SWITCH: return "switch";
        case TOKEN_UNION: return "union";
        case TOKEN_VOID: return "void";
        case TOKEN_WHILE: return "while";
        case TOKEN_IMPORT: return "import";
	case TOKEN_NEW: return "new";
    }

    puts("Unknown keyword in keyword_to_string: ");
    putsln(token_type_to_string(typ));
    exit(1);
}

fn location_init(loc: Location*, filename: char*, line: int, col: int) {
    loc.filename = filename;
    loc.line = line;
    loc.col = col;
}

fn location_print(loc: Location *) {
    puts(loc.filename);
    putc(':');
    putu(loc.line + 1);
    putc(':');
    putu(loc.col + 1);
}

fn die_loc2(eloc: char*, loc: Location*, msg1: char *, msg2: char *) {
    location_print(loc);
    puts(": ");
    puts(msg1);
    putsln(msg2);
    puts("Note: Error happened here: ");
    putsln(eloc);
    exit(1);
}

fn die_loc(eloc: char*, loc: Location*, msg: char *) {
    die_loc2(eloc, loc, msg, "");
}

fn token_from_type(token: Token*, typ: int, loc: Location *) {
    token.typ = typ;
}

fn token_from_int(token: Token*, val: int, loc: Location *) {
    token.typ = TOKEN_INTLIT;
    token.value.as_int = val;
    token.loc.filename = loc.filename;
    token.loc.line = loc.line;
    token.loc.col = loc.col;
}

fn token_from_string(token: Token*, str: char *, loc: Location *) {
    token.typ = TOKEN_STRINGLIT;
    token.value.as_string = str;
    token.loc.filename = loc.filename;
    token.loc.line = loc.line;
    token.loc.col = loc.col;
}

fn token_from_char(token: Token*, c: char, loc: Location *) {
    token.typ = TOKEN_CHARLIT;
    token.value.as_char = c;
    token.loc.filename = loc.filename;
    token.loc.line = loc.line;
    token.loc.col = loc.col;
}

fn token_from_identifier(token: Token*, str: char *, loc: Location *) {
    token.typ = TOKEN_IDENTIFIER;
    token.value.as_string = str;
    token.loc.filename = loc.filename;
    token.loc.line = loc.line;
    token.loc.col = loc.col;
}

fn is_literal_token(typ: int): int {
    switch (typ) {
        case TOKEN_INTLIT:
        case TOKEN_CHARLIT:
        case TOKEN_STRINGLIT:
        case TOKEN_FLOATLIT:
            return true;
        default:
            return false;
    }
}
