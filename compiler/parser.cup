import "compiler/lexer.cup"
import "compiler/ast.cup"

// p_ prefix for parser global variables.
let p_all_functions = vector_new();
let p_current_function: Node* = null;

let p_block_stack = vector_new();
let p_cur_stack_offset = 0;

let p_global_variables = vector_new();
let p_global_offset = 0;

let p_lexer_stack = vector_new();
let p_constant_stack = vector_new();
let p_compound_type_stack = vector_new();

let p_breakable_stack = vector_new();

// Default memory allocator for new
let p_default_allocator: char*;

// This prefix is added to functions which are constructors
fn add_prefix_new(s: char*): char*{
	let new_name: char* = malloc(sizeof(char)*5+sizeof(char)*strlen(s));
	let new_ = "new_";
	strcpy(new_name, new_);
	strcat(new_name, s);
	return new_name;
}

fn block_stack_push(block: Node*) {
    p_block_stack::push(block);
}

fn block_stack_pop() {
    let block: Node* = p_block_stack::pop();
    p_cur_stack_offset = p_cur_stack_offset - block.block.locals_size;
}

fn constant_push(name: char*, value: int) {
    let node = node_new(AST_CONSTANT);
    node.constant.name = name;
    node.constant.value = node_from_int_literal(value);
    p_constant_stack::push(node);
}

fn find_local_variable(name: char*): Variable* {
    if (p_current_function == null) return null;

    for (let i = p_block_stack.size - 1; i >= 0; --i) {
        let block: Node* = p_block_stack::at(i);
        for (let j = 0; j < block.block.locals.size; ++j) {
            let var: Variable* = block.block.locals::at(j);
            if (streq(name, var.name)) {
                return var;
            }
        }
    }

    let args = p_current_function.func.args;
    for (let i = 0; i < args.size; ++i) {
        let var: Variable* = args::at(i);
        if (streq(name, var.name)) {
            return var;
        }
    }

    return null;
}

fn find_compound_type(name: char*): Type* {
    for (let i = p_compound_type_stack.size - 1; i >= 0; --i) {
        let typ: Type* = p_compound_type_stack::at(i);
        if (streq(name, typ.struct_name)) {
            return typ;
        }
    }
    return null;
}

fn find_global_variable(name: char*): Variable* {
    for (let i = 0; i < p_global_variables.size; ++i) {
        let var: Variable* = p_global_variables::at(i);
        if (streq(name, var.name)) {
            return var;
        }
    }
    return null;
}

fn find_function_definition(name: char*, fn_list: Vector*): Node* {
    for (let i = 0; i < fn_list.size; ++i) {
        let func: Node* = fn_list::at(i);
        if (streq(name, func.func.name)) {
            return func;
        }
    }
    return null;
}

fn find_constant(name: char*): Node* {
    for (let i = 0; i < p_constant_stack.size; ++i) {
        let constant: Node* = p_constant_stack::at(i);
        if (streq(name, constant.constant.name)) {
            return constant;
        }
    }
    return null;
}

fn identifier_exists(name: char*): int {
    if (find_local_variable(name)) return true;
    if (find_global_variable(name)) return true;
    if (find_function_definition(name, p_all_functions)) return true;
    if (find_builtin_function(name)) return true;
    if (find_compound_type(name)) return true;
    if (find_constant(name)) return true;
    return false;
}

fn eval_constexp(node: Node*, token: Token*): int {
    if (node.typ == AST_LITERAL) {
        switch (node.etyp.typ) {
            case TYPE_INT: return node.literal.as_int;
            case TYPE_CHAR:  return node.literal.as_char;
        }
        die_loc(here, &token.loc, "Constant expressions can only contain integer literals/constants.");
    } else if (is_binary_op(node.typ)) {
        let left = eval_constexp(node.binary.lhs, token);
        let right = eval_constexp(node.binary.rhs, token);
        switch (node.typ) {
            case AST_PLUS: return left + right;
            case AST_MINUS: return left - right;
            case AST_BWOR: return left | right;
            case AST_BWAND: return left & right;
            case AST_XOR: return left ^ right;
            case AST_MUL: return left * right;
            case AST_DIV: return left / right;
            case AST_MOD: return left % right;
            case AST_MUL: return left * right;
            case AST_MUL: return left * right;
            case AST_EQ: return left == right;
            case AST_NEQ: return left != right;
            case AST_LT: return left < right;
            case AST_LEQ: return left <= right;
            case AST_GT: return left > right;
            case AST_GEQ: return left >= right;
            case AST_LSHIFT: return left << right;
            case AST_RSHIFT: return left >> right;
        }
        die_loc(here, &token.loc, "Unsupported binary operator in constant expression.");
    }
    if (node.typ == AST_NEG) return -eval_constexp(node.unary, token);
    if (node.typ == AST_BWINV) return ~eval_constexp(node.unary, token);
    if (node.typ == AST_NOT) return !eval_constexp(node.unary, token);
    die_loc(here, &token.loc, "Unsupported constant expression.");
}

fn parse_expression(lexer: Lexer*): Node*;

fn parse_constant_expression(lexer: Lexer*): i64 {
    let token: Token;
    lexer::peek(&token);
    let node = parse_expression(lexer);
    return eval_constexp(node, &token);
}

fn parse_constant_declaration(lexer: Lexer*): Node* {
    let token: Token;
    lexer::next_assert(&token, TOKEN_CONST);

    lexer::next_assert(&token, TOKEN_IDENTIFIER);
    if (identifier_exists(token.value.as_string))
        die_loc2(here, &token.loc, "Identifier already exists: ", token.value.as_string);
    let constant_name = token.value.as_string;

    lexer::peek(&token);
    // All constants are implicitly `int`, but we'll allow it for consistency
    if (token.typ == TOKEN_COLON) {
        lexer::next(&token);
        if (token.typ != TOKEN_INT)
            die_loc(here, &token.loc, "Expected 'int' type for constant");
        lexer::peek(&token);
    }

    lexer::next_assert(&token, TOKEN_ASSIGN);
    constant_push(constant_name, parse_constant_expression(lexer));

    lexer::next_assert(&token, TOKEN_SEMICOLON);
}

fn parse_literal(lexer: Lexer*): Node* {
    let token: Token;
    lexer::next(&token);
    let node = node_new(AST_LITERAL);

    switch (token.typ) {
        case TOKEN_INTLIT:
            node.literal.as_int = token.value.as_int;
            node.etyp = type_new(TYPE_INT);
            break;
        case TOKEN_STRINGLIT:
            node.literal.as_string = token.value.as_string;
            node.etyp = type_new_ptr(TYPE_CHAR);
            break;
        case TOKEN_CHARLIT:
            node.literal.as_char = token.value.as_char;
            node.etyp = type_new(TYPE_CHAR);
            break;
        case TOKEN_FLOATLIT:
            node.literal.as_string = token.value.as_float_str;
            node.etyp = type_new(TYPE_F64);
            break;
        default:
            die_loc2(here, &token.loc, "Unexpected token in parse_literal: ", token_type_to_string(token.typ));
    }
    return node;
}

fn parse_type(lexer: Lexer*): Type* {
    let token: Token;
    let typ: Type *;
    lexer::next(&token);

    static_assert(NUM_BASE_TYPES == 9, "Exhaustive handling of base types in parse_type");
    switch (token.typ) {
        case TOKEN_INT:  typ = type_new(TYPE_INT);  break;
        case TOKEN_I8:   typ = type_new(TYPE_I8);   break;
        case TOKEN_I16:  typ = type_new(TYPE_I16);  break;
        case TOKEN_I32:  typ = type_new(TYPE_I32);  break;
        case TOKEN_I64:  typ = type_new(TYPE_I64);  break;
        case TOKEN_F64:  typ = type_new(TYPE_F64);  break;
        case TOKEN_CHAR: typ = type_new(TYPE_CHAR); break;
        case TOKEN_VOID: typ = type_new(TYPE_VOID); break;
        default: {
            if (token.typ != TOKEN_IDENTIFIER)
                die_loc2(here, &token.loc, "Unexpected token in parse_type: ", token_type_to_string(token.typ));
            typ = find_compound_type(token.value.as_string);
            if (!typ)
                die_loc2(here, &token.loc, "Unknown token in parse_type: ", token.value.as_string);
        }
    }

    let running = true;
    while (running) {
        lexer::peek(&token);
        if (token.typ == TOKEN_STAR) {
            lexer::next(&token);
            let ptr = type_new(TYPE_PTR);
            ptr.ptr = typ;
            typ = ptr;
        } else if (token.typ == TOKEN_OPEN_BRACKET) {
            lexer::next(&token);
            let arr = type_new(TYPE_ARRAY);
            arr.ptr = typ;
            arr.array_size = parse_constant_expression(lexer);
            lexer::next_assert(&token, TOKEN_CLOSE_BRACKET);
            typ = arr;

        } else {
            running = false;
        }
    }
    return typ;
}

// NOTE: This is used for both functions / methods. For methods, we pass in
// `obj_ptr` here, which is injected as the first argument (implicit `self` pointer).
// For regular functions, we expect obj_ptr == null.
fn parse_function_call_args(lexer: Lexer*, func: Node*, obj_ptr: Node*): Node* {
    let token: Token;

    let node = node_new(AST_FUNCCALL);
    node.call.func = func;
    node.call.args = vector_new();
    node.etyp = func.etyp;

    lexer::next_assert(&token, TOKEN_OPEN_PAREN);
    lexer::peek(&token);

    if (obj_ptr)
        node.call.args::push(obj_ptr);

    while (token.typ != TOKEN_CLOSE_PAREN) {
        let arg = parse_expression(lexer);
        node.call.args::push(arg);

        lexer::peek(&token);

        if (token.typ == TOKEN_COMMA) {
            lexer::next(&token);
            lexer::peek(&token);
        }
    }
    lexer::next_assert(&token, TOKEN_CLOSE_PAREN);

    if (node.call.args.size != func.func.args.size)
        die_loc2(here, &token.loc, "Function call argument count mismatch: ", func.func.name);

    let n = func.func.args.size;
    for (let i = 0; i < n; ++i) {
        let arg: Node* = node.call.args::at(i);
        let var: Variable* = func.func.args::at(i);

        let conv = convert_type(var.typ, arg);
        if (!conv)
            die_loc2(here, &token.loc, "Function argument type mismatch: ", var.name);

        node.call.args.data[i] = conv;
    }

    return node;
}

fn parse_identifier(lexer: Lexer*): Node* {
    let token: Token;
    lexer::next_assert(&token, TOKEN_IDENTIFIER);
    let name = token.value.as_string;

    let node: Node*;
    let var = find_local_variable(name);
    if (var != null) {
        node = node_new(AST_LOCAL_VAR);
        node.variable = var;
        node.etyp = var.typ;
        return decay_array_to_pointer(node, &token);
    }

    var = find_global_variable(name);
    if (var != null) {
        node = node_new(AST_GLOBAL_VAR);
        node.variable = var;
        node.etyp = var.typ;
        return decay_array_to_pointer(node, &token);
    }

    let func = find_function_definition(name, p_all_functions);
    if (func != null) {
        return parse_function_call_args(lexer, func, null);
    }

    func = find_builtin_function(name);
    if (func != null) {
        return parse_function_call_args(lexer, func, null);
    }

    let constant = find_constant(name);
    if (constant != null) {
        // TODO: Make sure this is an integer
        return constant.constant.value;
    }

    die_loc2(here, &token.loc, "Unknown identifier in parse_identifier: ", token.value.as_string);
    return null;
}

fn parse_factor(lexer: Lexer*): Node* {
    let token: Token;
    let expr: Node*;
    lexer::peek(&token);

    if (token.typ == TOKEN_MINUS) {
        lexer::next(&token);
        expr = node_new(AST_NEG);
        expr.unary = parse_factor(lexer);
        expr = type_check_unary(expr, &token);

    } else if (token.typ == TOKEN_TILDE) {
        lexer::next(&token);
        expr = node_new(AST_BWINV);
        expr.unary = parse_factor(lexer);
        expr = type_check_unary(expr, &token);

    } else if (token.typ == TOKEN_PLUSPLUS) {
        lexer::next(&token);
        expr = node_new(AST_ASSIGN);
        expr.assign.lhs = parse_factor(lexer);
        if (!is_lvalue(expr.assign.lhs.typ))
            die_loc(here, &token.loc, "Cannot increment non-lvalue");

        let plus = node_new(AST_PLUS);
        plus.binary.lhs = expr.assign.lhs;
        plus.binary.rhs = node_from_int_literal(1);
        expr.assign.rhs = type_check_binary(plus, &token);
        expr.etyp = expr.assign.lhs.etyp;

    // --x is changed to (x = x - 1)
    } else if (token.typ == TOKEN_MINUSMINUS) {
        lexer::next(&token);
        expr = node_new(AST_ASSIGN);
        expr.assign.lhs = parse_factor(lexer);
        if (!is_lvalue(expr.assign.lhs.typ))
            die_loc(here, &token.loc, "Cannot decrement non-lvalue");

        let minus = node_new(AST_MINUS);
        minus.binary.lhs = expr.assign.lhs;
        minus.binary.rhs = node_from_int_literal(1);
        expr.assign.rhs = type_check_binary(minus, &token);
        expr.etyp = expr.assign.lhs.etyp;

    // FIXME: This should probably go somewhere else more appropriate
    } else if (token.typ == TOKEN_SIZEOF) {
        lexer::next(&token);
        lexer::next_assert(&token, TOKEN_OPEN_PAREN);
        let typ = parse_type(lexer);
        lexer::next_assert(&token, TOKEN_CLOSE_PAREN);
        expr = node_from_int_literal(size_for_type(typ));

    } else if (token.typ == TOKEN_EXCLAMATION) {
        lexer::next(&token);
        expr = node_new(AST_NOT);
        expr.unary = parse_factor(lexer);
        expr = type_check_unary(expr, &token);

    } else if (token.typ == TOKEN_OPEN_PAREN) {
        lexer::next(&token);
        expr = parse_expression(lexer);
        lexer::next_assert(&token, TOKEN_CLOSE_PAREN);

    } else if (is_literal_token(token.typ)) {
        expr = parse_literal(lexer);

    } else if (token.typ == TOKEN_IDENTIFIER) {
        expr = parse_identifier(lexer);

    } else if (token.typ == TOKEN_AMPERSAND) {
        lexer::next(&token);
        expr = node_new(AST_ADDROF);
        expr.unary = parse_factor(lexer);
        if (!is_lvalue(expr.unary.typ))
            die_loc(here, &token.loc, "Cannot take address of non-lvalue");
        expr = type_check_unary(expr, &token);

    } else if (token.typ == TOKEN_STAR) {
        lexer::next(&token);
        let subexp = parse_factor(lexer);
        if (subexp.etyp.typ != TYPE_PTR)
            die_loc(here, &token.loc, "Cannot dereference non-pointer type");

        expr = node_new(AST_DEREF);
        expr.unary = subexp;
        expr = type_check_unary(expr, &token);

    } else if (token.typ == TOKEN_NEW){
		lexer::next(&token);
		lexer::next_assert(&token, TOKEN_IDENTIFIER);
		let struct_name: Token*;
		struct_name = &token;
		
		// Check whether that struct even exists in the first place
		let struct_constructed = find_compound_type(struct_name.value.as_string);
			if (struct_constructed == null)
				die_loc2(here, &struct_name.loc, "Could not find struct/union with name: ", struct_name.value.as_string);
		
		// All constructors have that prefix
		let full_name: char* = add_prefix_new(struct_name.value.as_string);
		let func = find_function_definition(full_name, p_all_functions);
		free(full_name);
		if (func != null){
			if (!func.func.is_constructor){
				die_loc2(here, &struct_name.loc, "Could not find constructor for struct: ", struct_name.value.as_string);
			}
			expr = parse_function_call_args(lexer, func, null);
		} else{
			die_loc2(here, &struct_name.loc, "Could not find constructor for struct: ", struct_name.value.as_string);
		}
	}
	else {
        die_loc2(here, &token.loc, ": Unexpected token found in parse_factor: ", token_type_to_string(token.typ));
    }

    let running = true;
    while (running) {
        lexer::peek(&token);
        if (token.typ == TOKEN_OPEN_BRACKET) {
            if (expr.etyp.typ != TYPE_PTR)
                die_loc(here, &token.loc, "Cannot index non-pointer/array type");
            lexer::next(&token);

            let index = parse_expression(lexer);

            let offset = node_new(AST_PLUS);
            offset.binary.lhs = expr;
            offset.binary.rhs = index;
            offset = type_check_binary(offset, &token);

            expr = node_new(AST_DEREF);
            expr.unary = offset;
            expr = type_check_unary(expr, &token);

            lexer::next_assert(&token, TOKEN_CLOSE_BRACKET);

        } else if (token.typ == TOKEN_DOT) {
            lexer::next_assert(&token, TOKEN_DOT);
            if (!is_struct_or_structptr(expr.etyp)) {
                putsln(create_type_string(expr.etyp));
                die_loc(here, &token.loc, "Cannot access member of non-struct type");
            }

            let is_ptr = expr.etyp.typ == TYPE_PTR;
            let struct_type = is_ptr ? expr.etyp.ptr : expr.etyp;

            lexer::next_assert(&token, TOKEN_IDENTIFIER);
            let name = token.value.as_string;
            let field = compound_find_field(struct_type, name);

            if (field == null) {
                puts("Struct type: "); putsln(create_type_string(struct_type));
                puts("Field name: "); putsln(name);
                die_loc(here, &token.loc, "Invalid field name for struct");
            }

            let member = node_new(AST_MEMBER);
            member.etyp = field.typ;
            member.member.obj = expr;
            member.member.offset = field.offset;
            member.member.is_ptr = (expr.etyp.typ == TYPE_PTR);

            expr = decay_array_to_pointer(member, &token);

        } else if (token.typ == TOKEN_COLONCOLON) {
            lexer::next(&token);

            if (!is_struct_or_structptr(expr.etyp))
                die_loc(here, &token.loc, "Cannot call method on non-struct type");

            let struct_type: Type*;
            let obj_ptr: Node*;

            if (expr.etyp.typ == TYPE_PTR) {
                struct_type = expr.etyp.ptr;
                obj_ptr = expr;
            } else {
                struct_type = expr.etyp;
                obj_ptr = node_new(AST_ADDROF);
                obj_ptr.unary = expr;
                obj_ptr = type_check_unary(obj_ptr, &token);
            }

            lexer::next_assert(&token, TOKEN_IDENTIFIER);
            let name = token.value.as_string;
            let _method = compound_find_method(struct_type, name);
            if (_method == null)
                die_loc(here, &token.loc, "Invalid method name for struct");

            expr = parse_function_call_args(lexer, _method, obj_ptr);

        } else {
            running = false;
        }
    }

    return expr;
}

// This is absolutely terrible, but I'm not sure how to do it better without macros...
fn parse_term(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_factor(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_STAR || token.typ == TOKEN_SLASH || token.typ == TOKEN_PERCENT) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_factor(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_additive(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_term(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_PLUS || token.typ == TOKEN_MINUS || token.typ == TOKEN_LSHIFT || token.typ == TOKEN_RSHIFT) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_term(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_relational(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_additive(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_LT || token.typ == TOKEN_LEQ ||
           token.typ == TOKEN_GT || token.typ == TOKEN_GEQ) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_additive(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_equality(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_relational(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_EQ || token.typ == TOKEN_NEQ) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_relational(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_and(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_equality(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_AMPERSAND) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_equality(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_exclusive_or(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_and(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_CARET) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_and(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_inclusive_or(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_exclusive_or(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_BAR) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_exclusive_or(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_logical_and(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_inclusive_or(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_AND) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_inclusive_or(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_logical_or(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_logical_and(lexer);
    lexer::peek(&token);
    while (token.typ == TOKEN_OR) {
        lexer::next(&token);
        let op = node_new(binary_token_to_op(token.typ));
        let rhs = parse_logical_and(lexer);
        op.binary.lhs = lhs;
        op.binary.rhs = rhs;
        lhs = type_check_binary(op, &token);
        lexer::peek(&token);
    }
    return lhs;
}

fn parse_conditional_exp(lexer: Lexer*): Node* {
    let token: Token;

    let lhs = parse_logical_or(lexer);
    lexer::peek(&token);
    if (token.typ == TOKEN_QUESTION) {
        lexer::next(&token);
        let then = parse_expression(lexer);
        lexer::next_assert(&token, TOKEN_COLON);
        let els = parse_expression(lexer);

        let cond = node_new(AST_CONDITIONAL);
        cond.conditional.cond = lhs;
        cond.conditional.then = then;
        cond.conditional.els = els;

        if (!types_equal(then.etyp, els.etyp))
            die_loc(here, &token.loc, "THEN and ELSE branches of conditional expression have different types");

        lhs = cond;
        lhs.etyp = then.etyp;
    }
    return lhs;
}

fn parse_expression(lexer: Lexer*): Node* {
    let lhs = parse_conditional_exp(lexer);
    if (is_lvalue(lhs.typ)) {
        let token: Token;
        lexer::peek(&token);
        if (token.typ == TOKEN_ASSIGN) {
            lexer::next(&token);
            let node = node_new(AST_ASSIGN);
            let rhs = parse_expression(lexer);

            let conv = convert_type(lhs.etyp, rhs);
            if (!conv) {
                puts("- LHS type: "); putsln(create_type_string(lhs.etyp));
                puts("- RHS type: "); putsln(create_type_string(rhs.etyp));
                die_loc(here, &token.loc, "Type mismatch for variable assignment");
            }
            node.etyp = lhs.etyp;
            node.assign.lhs = lhs;
            node.assign.rhs = conv;
            lhs = node;
        }
    }
    return lhs;
}

fn add_variable_to_current_block(var: Variable*) {
    // Set offset for variable
    let cur_block: Node* = p_block_stack::top();
    let var_size = align_up(size_for_type(var.typ), 8);

    // Add to the block
    // FIXME: Use a map here
    cur_block.block.locals::push(var);

    assert(here, p_current_function != null);
    // Update current stack offset (w.r.t function stack frame) and block size
    p_cur_stack_offset = p_cur_stack_offset + var_size;
    cur_block.block.locals_size = cur_block.block.locals_size + var_size;
    var.offset = p_cur_stack_offset;

    // Update function's max locals size
    let max_offset = max(p_current_function.func.max_locals_size, p_cur_stack_offset);
    p_current_function.func.max_locals_size = max_offset;
}

fn add_global_variable(var: Variable*) {
    var.offset = p_global_offset;
    let var_size = align_up(size_for_type(var.typ), 8);
    p_global_offset = p_global_offset + var_size;
    p_global_variables::push(var);
}

fn parse_var_declaration(lexer: Lexer*): Node* {

    let token: Token;
    lexer::next_assert(&token, TOKEN_LET);
    lexer::next_assert(&token, TOKEN_IDENTIFIER);

    if (identifier_exists(token.value.as_string))
        die_loc2(here, &token.loc, "Identifier already defined: %s", token.value.as_string);

    let is_global = (p_current_function == null);

    let node = node_new(AST_VARDECL);
    let decl = &node.var_decl;
    decl.var.name = token.value.as_string;

    lexer::peek(&token);
    let missing_type = true;
    if (token.typ == TOKEN_COLON) {
        lexer::next(&token);
        decl.var.typ = parse_type(lexer);
        missing_type = false;
        lexer::peek(&token);
    }

    if (token.typ == TOKEN_ASSIGN) {
        lexer::next(&token);
        decl.init = parse_expression(lexer);

        if (missing_type) {
            decl.var.typ = decl.init.etyp;
        } else {
            let conv = convert_type(decl.var.typ, decl.init);
            if (!conv) {
                puts("- Variable type: "); putsln(create_type_string(decl.var.typ));
                puts("- Value type: "); putsln(create_type_string(decl.init.etyp));
                die_loc2(here, &token.loc, "Type mismatch for variable declaration: ", decl.var.name);
            }
            decl.init = conv;
        }

        node.etyp = decl.init.etyp;
    } else if (missing_type) {
        die_loc(here, &token.loc, "Expected ':' or '=' after variable declaration");
    }

    if (is_global) {
        add_global_variable(&decl.var);
    } else {
        add_variable_to_current_block(&decl.var);
    }

    return node;
}

fn parse_function_params(lexer: Lexer*, func: Node*) {
    let token: Token;
    lexer::peek(&token);

    if (!func.func.args)
        func.func.args = vector_new();

    while (token.typ != TOKEN_CLOSE_PAREN) {
        lexer::next_assert(&token, TOKEN_IDENTIFIER);
        let name = token.value.as_string;

        if (identifier_exists(token.value.as_string))
            die_loc2(here, &token.loc, "Identifier already defined: ", name);

        lexer::next_assert(&token, TOKEN_COLON);
        let typ = parse_type(lexer);

        let var: Variable* = malloc(sizeof(Variable));
        var.name = name;
        var.typ = typ;
        func.func.args::push(var);

        lexer::peek(&token);
        if (token.typ == TOKEN_COMMA) {
            lexer::next(&token);
            lexer::peek(&token);
        }
    }

    // Set the offsets for the arguments

    // IMPORTANT: We want to skip the saved ret_addr+old_rbp that we
    //            pushed on the stack. Each of these is 8 bytes.
    let offset = -16;
    let n = func.func.args.size;
    for (let i = 0; i < n; ++i) {
        let var: Variable* = func.func.args::at(i);
        var.offset = offset;
        // TODO: (Here and other uses of `size_for_type`):
        //      Should we only align to max(8, type.size) instead?
        let var_size = align_up(size_for_type(var.typ), 8);
        offset = offset - var_size;
    }
}

fn parse_block(lexer: Lexer*): Node*;
fn parse_statement(lexer: Lexer*): Node*;

fn parse_switch_statement(lexer: Lexer*): Node* {
    let token: Token;
    lexer::next_assert(&token, TOKEN_SWITCH);

    let node = node_new(AST_SWITCH);
    lexer::next_assert(&token, TOKEN_OPEN_PAREN);
    node.switch_stmt.expr = parse_expression(lexer);

    if (!is_int_type(node.switch_stmt.expr.etyp))
        die_loc(here, &token.loc, "Expected integer-like expression for switch statement");

    node.switch_stmt.cases = vector_new();
    p_breakable_stack::push(node);

    lexer::next_assert(&token, TOKEN_CLOSE_PAREN);

    lexer::next_assert(&token, TOKEN_OPEN_BRACE);

    lexer::peek(&token);
    while (token.typ != TOKEN_CLOSE_BRACE) {
        if (token.typ == TOKEN_CASE) {
            lexer::next(&token);

            let case_stmt = node_new(AST_CASE);
            case_stmt.case_stmt.val = parse_constant_expression(lexer);
            case_stmt.case_stmt.children = vector_new();

            lexer::next_assert(&token, TOKEN_COLON);
            lexer::peek(&token);
            while (token.typ != TOKEN_CASE &&
                   token.typ != TOKEN_DEFAULT &&
                   token.typ != TOKEN_CLOSE_BRACE) {
                let stmt = parse_statement(lexer);
                case_stmt.case_stmt.children::push(stmt);
                lexer::peek(&token);
            }

            node.switch_stmt.cases::push(case_stmt);

        } else if (token.typ == TOKEN_DEFAULT) {
            node.switch_stmt.defolt = vector_new();

            lexer::next(&token);
            lexer::next_assert(&token, TOKEN_COLON);
            lexer::peek(&token);
            while (token.typ != TOKEN_CASE &&
                   token.typ != TOKEN_DEFAULT &&
                   token.typ != TOKEN_CLOSE_BRACE) {
                let stmt = parse_statement(lexer);
                node.switch_stmt.defolt::push(stmt);
                lexer::peek(&token);
            }
            if (token.typ != TOKEN_CLOSE_BRACE)
                die_loc(here, &token.loc, "Shouldn't have any more case statments after 'default'. Expected '}'");

        } else {
            die_loc(here, &token.loc, "Expected 'case' or 'default'");
        }
    }

    p_breakable_stack::pop();
    lexer::next_assert(&token, TOKEN_CLOSE_BRACE);
    return node;
}

fn parse_for_loop(lexer: Lexer*): Node* {
    let token: Token;
    lexer::next_assert(&token, TOKEN_FOR);

    let looop = node_new(AST_FOR);
    lexer::next_assert(&token, TOKEN_OPEN_PAREN);

    // NOTE: We're going to put the for loop in it's own block
    //       so that any declarations in the init of the loop
    //       can only be referenced within the loop.
    let node = node_new(AST_BLOCK);
    node.block.children = vector_new_sized(1);
    node.block.locals = vector_new_sized(1);
    block_add_child(node, looop);
    block_stack_push(node);

    // All of the expressions in the for loop are optional

    lexer::peek(&token);
    if (token.typ == TOKEN_LET)
        looop.looop.init = parse_var_declaration(lexer);
    else if (token.typ != TOKEN_SEMICOLON)
        looop.looop.init = parse_expression(lexer);
    lexer::next_assert(&token, TOKEN_SEMICOLON);

    lexer::peek(&token);
    if (token.typ != TOKEN_SEMICOLON)
        looop.looop.cond = parse_expression(lexer);
    lexer::next_assert(&token, TOKEN_SEMICOLON);

    lexer::peek(&token);
    if (token.typ != TOKEN_CLOSE_PAREN)
        looop.looop.step = parse_expression(lexer);
    lexer::next_assert(&token, TOKEN_CLOSE_PAREN);

    p_breakable_stack::push(looop);
    looop.looop.body = parse_statement(lexer);
    p_breakable_stack::pop();
    block_stack_pop();

    return node;
}

fn handle_static_assert(lexer: Lexer*) {
    let token: Token;
    lexer::next(&token);
    lexer::next_assert(&token, TOKEN_OPEN_PAREN);

    let res = parse_constant_expression(lexer);
    lexer::next_assert(&token, TOKEN_COMMA);
    let message = parse_expression(lexer);

    if (message.typ != AST_LITERAL || message.etyp.typ != TYPE_PTR)
        die_loc(here, &token.loc, "Assertion message must be a string");

    if (!res) {
        location_print(&token.loc);
        puts(": Static assertion failed: \"");
        puts(message.literal.as_string);
        putsln("\"");
        exit(1);
    }

    lexer::next_assert(&token, TOKEN_CLOSE_PAREN);
    lexer::next_assert(&token, TOKEN_SEMICOLON);
}

fn parse_statement(lexer: Lexer*): Node* {
    let node: Node*;
    let token: Token;

    lexer::peek(&token);
    if (token.typ == TOKEN_OPEN_BRACE) {
        node = parse_block(lexer);
        lexer::peek(&token);
        if (token.typ == TOKEN_SEMICOLON)
            lexer::next(&token);

    } else if (token.typ == TOKEN_RETURN) {
        lexer::next(&token);
        node = node_new(AST_RETURN);

        lexer::peek(&token);
        if (token.typ != TOKEN_SEMICOLON) {
            node.unary = parse_expression(lexer);
            let conv = convert_type(p_current_function.etyp, node.unary);
            if (!conv)
                die_loc(here, &token.loc, "Returned expression cannot be implicitly converted to function's return type.");
            node.unary = conv;
        } else {
            node.unary = null; // empty return statment
            if (p_current_function.etyp.typ != TYPE_VOID) {
                puts("Expected return type: "); putsln(create_type_string(p_current_function.etyp));
                die_loc(here, &token.loc, "Can't have an empty return statement in a non-void function");
            }
        }
        node.etyp = p_current_function.etyp;
        lexer::next_assert(&token, TOKEN_SEMICOLON);

    } else if (token.typ == TOKEN_IF) {
        lexer::next(&token);

        node = node_new(AST_IF);

        lexer::next_assert(&token, TOKEN_OPEN_PAREN);
        node.conditional.cond = parse_expression(lexer);
        lexer::next_assert(&token, TOKEN_CLOSE_PAREN);
        node.conditional.then = parse_statement(lexer);

        lexer::peek(&token);
        if (token.typ == TOKEN_ELSE) {
            lexer::next(&token);
            node.conditional.els = parse_statement(lexer);
        }
    } else if (token.typ == TOKEN_WHILE) {
        lexer::next(&token);
        node = node_new(AST_WHILE);
        lexer::next_assert(&token, TOKEN_OPEN_PAREN);
        node.looop.cond = parse_expression(lexer);
        lexer::next_assert(&token, TOKEN_CLOSE_PAREN);

        p_breakable_stack::push(node);
        node.looop.body = parse_statement(lexer);
        p_breakable_stack::pop();

    } else if (token.typ == TOKEN_FOR) {
        node = parse_for_loop(lexer);

    } else if (token.typ == TOKEN_SWITCH) {
        node = parse_switch_statement(lexer);

    } else if (token.typ == TOKEN_BREAK) {
        lexer::next(&token);
        if (p_breakable_stack::empty())
            die_loc(here, &token.loc, "Can't break outside of a loop / switch statement");
        node = node_new(AST_BREAK);
        lexer::next_assert(&token, TOKEN_SEMICOLON);

    } else if (token.typ == TOKEN_DEFER) {
        lexer::next_assert(&token, TOKEN_DEFER);
        node = node_new(AST_DEFER);
        node.unary = parse_statement(lexer);

    } else if (token.typ == TOKEN_LET) {
        node = parse_var_declaration(lexer);
        lexer::next_assert(&token, TOKEN_SEMICOLON);

    } else if (token.typ == TOKEN_STATIC_ASSERT) {
        handle_static_assert(lexer);
        node = null;

    } else {
        // Default to expression statement
        node = parse_expression(lexer);
        lexer::next_assert(&token, TOKEN_SEMICOLON);
    }
    return node;
}

fn parse_block(lexer: Lexer*): Node* {
    let token: Token;
    lexer::next_assert(&token, TOKEN_OPEN_BRACE);

    let block = node_new(AST_BLOCK);
    block.block.children = vector_new();
    block.block.locals = vector_new();

    block_stack_push(block);

    lexer::peek(&token);
    while (token.typ != TOKEN_CLOSE_BRACE) {
        let child = parse_statement(lexer);
        if (child)
            block_add_child(block, child);
        lexer::peek(&token);
    }
    lexer::next_assert(&token, TOKEN_CLOSE_BRACE);

    block_stack_pop();
    return block;
}

fn parse_enum_declaration(lexer: Lexer*) {
    let token: Token;
    // FIXME: This is all a hack to automatically number
    //        Some constants. It does not behave like a type,
    //        and cannot be used as one. Fix this in the future.
    lexer::next_assert(&token, TOKEN_ENUM);
    lexer::next_assert(&token, TOKEN_IDENTIFIER); // Use this!
    lexer::next_assert(&token, TOKEN_OPEN_BRACE);

    let enum_count = 0;
    lexer::peek(&token);
    while (token.typ != TOKEN_CLOSE_BRACE) {
        lexer::next_assert(&token, TOKEN_IDENTIFIER);

        if (identifier_exists(token.value.as_string))
            die_loc(here, &token.loc, "Identifier already exists, enums just behave like numbered constants.");

        constant_push(token.value.as_string, enum_count);
        ++enum_count;

        lexer::peek(&token);
        if (token.typ == TOKEN_COMMA) {
            lexer::next(&token);
            lexer::peek(&token);
        } else if (token.typ != TOKEN_CLOSE_BRACE) {
            die_loc(here, &token.loc, "Expected a comma or a closing brace.");
        }
    }
    lexer::next_assert(&token, TOKEN_CLOSE_BRACE);
}

// FIXME: This should just be part of `parse_type()`, and we should be allowed
//        to parse a type without a name. Probably also need to handle converstions
//        between structs with similar embedded types.
fn parse_struct_union_declaration(lexer: Lexer*, top_level: int, base_offset: int): Type* {
    let token: Token;
    lexer::next(&token);

    if (token.typ != TOKEN_STRUCT && token.typ != TOKEN_UNION)
        die_loc(here, &token.loc, "Expected STRUCT or UNION in parse_struct_union_declaration");

    let compound = type_new(token.typ == TOKEN_STRUCT ? TYPE_STRUCT : TYPE_UNION);
    compound.fields = vector_new();
    compound.methods = vector_new();

    lexer::peek(&token);

    // For nested temporary structs we don't need a name
    if (token.typ != TOKEN_IDENTIFIER && top_level)
        die_loc(here, &token.loc, "You need to specify a name for the struct defined globally.");

    // But if they do provide one, we'll add it to the list of defined structs so they
    // it can referenced internally.
    if (token.typ == TOKEN_IDENTIFIER) {
        compound.struct_name = token.value.as_string;
        p_compound_type_stack::push(compound);
        lexer::next(&token);
    } else {
        compound.struct_name = "<anon>";
    }

    lexer::next_assert(&token, TOKEN_OPEN_BRACE);

    lexer::peek(&token);
    while (token.typ != TOKEN_CLOSE_BRACE) {
        lexer::peek(&token);
        let name: char* = null;

        // We have a named field.
        if (token.typ == TOKEN_IDENTIFIER) {
            lexer::next(&token);
            // TODO: Make sure the name doesn't conflict with an existing field. This is a bit
            //       more annoying than it sounds because we have no-named types.
            name = token.value.as_string;
            lexer::next_assert(&token, TOKEN_COLON);
            lexer::peek(&token);
        }


        // We want to allow nested temporary structs.
        let typ: Type*;
        if (token.typ == TOKEN_STRUCT || token.typ == TOKEN_UNION) {
            // Compute the "base offset" for the nested struct, which is the offset from the start
            // of the struct the last **named** field in the heirarchy above
            let cur_base_offset = 0;
            if (name == null) {
                cur_base_offset = base_offset + (compound.typ == TYPE_UNION ? 0 : compound.size);
            }

            // If the field didn't have a name, we can assign one now, since we know it's a
            // temporary struct. This name will never be directly referenced, so it's fine.
            if (name == null)
                name = "<anon>";

            // Nested structs live in their own "namespace", can't be accessed
            // from outside, so we will pop them off the stack once done.
            let prev_compound_count = p_compound_type_stack.size;
            typ = parse_struct_union_declaration(lexer, false, cur_base_offset);
            p_compound_type_stack.size = prev_compound_count;

        } else if (name != null) {
            typ = parse_type(lexer);
        } else {
            die_loc(here, &token.loc, "Expected a name for a non-compound field in a struct/union.");
        }

        compound_push_field(compound, name, typ, base_offset);
        lexer::next_assert(&token, TOKEN_SEMICOLON);
        lexer::peek(&token);
    }
    lexer::next_assert(&token, TOKEN_CLOSE_BRACE);
    return compound;
}

// FIXME: Should probably combine this with `parse_function()`, there's a _lot_ of.
// FIXME: Just implement a proper multi-pass compiler so we don't need to handle the
//        stupid declarations separately.
fn parse_method(lexer: Lexer*): Node* {
    let token: Token;

    lexer::next_assert(&token, TOKEN_METHOD);
    lexer::next_assert(&token, TOKEN_IDENTIFIER);

    let ctyp = find_compound_type(token.value.as_string);
    if (ctyp == null)
        die_loc2(here, &token.loc, "Could not find struct/union with name: ", token.value.as_string);

    lexer::next_assert(&token, TOKEN_COLONCOLON);
    lexer::next_assert(&token, TOKEN_IDENTIFIER);

    let func = node_new(AST_FUNC);
    func.func.name = token.value.as_string;
    func.func.is_method = true;
    func.func.method_of = ctyp;
    func.func.args = vector_new();

    // If the identifier exists, there's 3 possible cases:
    //  1. It's a method that's been defined, which is an error.
    //  2. It's a method that's been declared (but not defined), which is OK
    let dfunc = find_function_definition(token.value.as_string, ctyp.methods);
    if (dfunc != null) {
        // Case 1
        if (dfunc.func.is_defined)
            die_loc(here, &token.loc, "Method already defined earlier");

        // TODO: Check if the method signature matches
        // Case 2 (No error, just set the current function correctly)
        p_current_function = func;
    } else {
        // We don't want to add this to `all_functions`, since we only want it to be accessible
        // for the struct/union that it is a method of. We'll add it to the struct/union's
        // `methods` vector instead.
        ctyp.methods::push(func);
        p_current_function = func;
    }

    let ptr_typ = type_new(TYPE_PTR);
    ptr_typ.ptr = ctyp;

    let self_var = variable_new("self", ptr_typ, 0);
    func.func.args::push(self_var);

    lexer::next_assert(&token, TOKEN_OPEN_PAREN);
    parse_function_params(lexer, func);
    lexer::next_assert(&token, TOKEN_CLOSE_PAREN);

    lexer::peek(&token);
    if (token.typ == TOKEN_COLON) {
        lexer::next(&token);
        func.etyp = parse_type(lexer);
    } else {
        func.etyp = type_new(TYPE_VOID);
    }

    lexer::peek(&token);
    if (token.typ == TOKEN_OPEN_BRACE) {
        func.func.body = parse_block(lexer);
        func.func.is_defined = true;
    } else {
        func.func.is_defined = false;
    }

    p_current_function = null;
    return func;
}

// FIXME: Combine with parse_function
fn parse_constructor(lexer: Lexer*): Node* {
    let token: Token;

    lexer::next_assert(&token, TOKEN_IDENTIFIER);
	
	let struct_constructed = find_compound_type(token.value.as_string);
			if (struct_constructed == null)
				die_loc2(here, &token.loc, "Could not find struct/union with name: ", token.value.as_string);

    let func = node_new(AST_FUNC);
    func.func.name = token.value.as_string;
	func.func.name = add_prefix_new(token.value.as_string);
	func.func.is_constructor = true;

    // Check if function with that name already have been defined
	let dfunc = find_function_definition(func.func.name, p_all_functions);
    if (dfunc != null) {
        // Function was already defined
        if (dfunc.func.is_defined)
            die_loc(here, &token.loc, "Function already defined earlier");

        // It wasn't so we put our own definition
        p_current_function = func;
    } else {
        // We don't have a declaration yet, push this.
        p_all_functions::push(func);
        p_current_function = func;
    }

    lexer::next_assert(&token, TOKEN_OPEN_PAREN);
    parse_function_params(lexer, func);
    lexer::next_assert(&token, TOKEN_CLOSE_PAREN);

	// Instead of trying to search for return type we simply set it to struct pointer we are constructing 
	let ptr_type = type_new(TYPE_PTR);
	ptr_type.ptr = struct_constructed;
	func.etyp = ptr_type;

    lexer::peek(&token);
    if (token.typ == TOKEN_OPEN_BRACE) {
        func.func.body = parse_block(lexer);
        func.func.is_defined = true;
    } else {
        func.func.is_defined = false;
    }

    p_current_function = null;
    return func;
}

fn parse_function(lexer: Lexer*): Node* {
    let token: Token;

    lexer::next_assert(&token, TOKEN_FN);
    lexer::next_assert(&token, TOKEN_IDENTIFIER);

    let func = node_new(AST_FUNC);
    let dfunc = func;
    func.func.name = token.value.as_string;

    // If the identifier exists, there's 3 possible cases:
    //  1. It's another variable / struct, which is an error.
    //  2. It's a function that's been defined, which is an error.
    //  3. It's a function that's been declared (but not defined), which is OK
    if (identifier_exists(token.value.as_string)) {
        dfunc = find_function_definition(token.value.as_string, p_all_functions);
        // Case 1
        if (dfunc == null)
            die_loc(here, &token.loc, "Function name already exists as an identifier");
        // Case 2
        if (dfunc.func.is_defined)
            die_loc(here, &token.loc, "Function already defined earlier");

        // Case 3 (No error, just set the current function correctly)
        p_current_function = func;
    } else {
        // We don't have a declaration yet, push this.
        p_all_functions::push(func);
        p_current_function = func;
    }

    lexer::next_assert(&token, TOKEN_OPEN_PAREN);
    parse_function_params(lexer, func);
    lexer::next_assert(&token, TOKEN_CLOSE_PAREN);

    lexer::peek(&token);
    if (token.typ == TOKEN_COLON) {
        lexer::next(&token);
        func.etyp = parse_type(lexer);
    } else {
        func.etyp = type_new(TYPE_VOID);
    }

    lexer::peek(&token);
    if (token.typ == TOKEN_OPEN_BRACE) {
        func.func.body = parse_block(lexer);
        func.func.is_defined = true;
    } else {
        func.func.is_defined = false;
    }

    p_current_function = null;
    return func;
}

// Parses cdefault statement which essentially sets some parameters for compilation
fn parse_cdefault(lexer: Lexer*): Node*{
	let token: Token;
	
	lexer::next_assert(&token, TOKEN_CDEFAULT);
	lexer::next_assert(&token, TOKEN_IDENTIFIER);
	
	// Sets default allocator for new
	if (streq(token.value.as_string, "allocator")){
		lexer::next_assert(&token, TOKEN_IDENTIFIER);
		let dfunc = find_function_definition(token.value.as_string, p_all_functions);
		if (dfunc == null){
			die_loc(here, &token.loc, "This allocator function doesn't exist!");
		} else {
			p_default_allocator = token.value.as_string;
		}
	}
	else {
		die_loc(here, &token.loc, "This cdefault paramater doesn't exist!");
	}
	
	lexer::next_assert(&token, TOKEN_SEMICOLON);
	
	// This doesn't really generate a node so
	return null;
}

let p_opened_files = vector_new();

fn parser_open_new_file(path: char*) {
    for (let i = 0; i < p_lexer_stack.size; i = i + 1) {
        let lex: Lexer* = p_lexer_stack::at(i);
        if (streq(lex.filename, path)) {
            puts("Found a circular import dependency in: "); puts(path); putsln(": Exiting.");
            exit(1);
        }
    }
    for (let i = 0; i < p_opened_files.size; i = i + 1) {
        if (streq(p_opened_files::at(i), path)) {
            // Already opened this file, ignore
            return;
        }
    }
    p_opened_files::push(path);
    p_lexer_stack::push(lexer_new_open_file(path));
}

fn parse_program(lexer: Lexer*): Node* {
    initialize_builtins();

    let node = node_new(AST_PROGRAM);
    node.block.children = vector_new();

    let token: Token;
    lexer::peek(&token);
    p_lexer_stack::push(lexer);

    while (token.typ != TOKEN_EOF) {
        let child = null;
        if (token.typ == TOKEN_FN) {
            child = parse_function(lexer);
        } else if (token.typ == TOKEN_METHOD) {
            child = parse_method(lexer);
        } else if (token.typ == TOKEN_IDENTIFIER){
			child = parse_constructor(lexer);
		} else if (token.typ == TOKEN_LET) {
            child = parse_var_declaration(lexer);
        } else if (token.typ == TOKEN_SEMICOLON) {
            lexer::next(&token);
        } else if (token.typ == TOKEN_CONST) {
            parse_constant_declaration(lexer);
        } else if (token.typ == TOKEN_STATIC_ASSERT) {
            handle_static_assert(lexer);
        } else if (token.typ == TOKEN_IMPORT) {
            lexer::next(&token);
            lexer::next_assert(&token, TOKEN_STRINGLIT);
            let path = token.value.as_string;
            parser_open_new_file(path);
            lexer = p_lexer_stack::top();
        } else if (token.typ == TOKEN_STRUCT || token.typ == TOKEN_UNION) {
            parse_struct_union_declaration(lexer, true, 0);
        } else if (token.typ == TOKEN_ENUM) {
            parse_enum_declaration(lexer);
        } else if (token.typ == TOKEN_CDEFAULT){
			child = parse_cdefault(lexer);
		}
		else {
            die_loc2(here, &token.loc, "unexpected token in parse_program: ", token_type_to_string(token.typ));
        }

        if (child)
            block_add_child(node, child);

        lexer::peek(&token);
        while (token.typ == TOKEN_EOF && p_lexer_stack.size > 1) {
            p_lexer_stack::pop();
            lexer = p_lexer_stack::top();
            lexer::peek(&token);
        }
    }
    return node;
}